{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Computer Vision Assignment2 - Non Local Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time \n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Noise Image generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "img_list = []\n",
    "for i,file_name in enumerate(os.listdir(\"./data\")) :\n",
    "    image = plt.imread(\"./data/\" + file_name)\n",
    "    img_list.append(image)\n",
    "\n",
    "w1,h1,_ = img_list[0].shape\n",
    "w2,h2,_ = img_list[1].shape\n",
    "\n",
    "# get gaussian noise\n",
    "mean = 0\n",
    "std_list = [20,30,40]\n",
    "noise_img_list_1 = []\n",
    "noise_img_list_2 = []\n",
    "\n",
    "#image with noise \n",
    "for std in std_list :   \n",
    "    noise1 = np.random.normal(mean,std,img_list[0].shape)\n",
    "    noise2 = np.random.normal(mean,std,img_list[1].shape)\n",
    "    img1 = np.array(img_list[0], copy=True) \n",
    "    img2 = np.array(img_list[1], copy=True)\n",
    "    cv2.normalize(noise1,noise1,0,255,norm_type=cv2.NORM_MINMAX)\n",
    "    cv2.normalize(noise2,noise2,0,255,norm_type=cv2.NORM_MINMAX)\n",
    "    cv2.normalize(img1,img1,0,255,norm_type=cv2.NORM_MINMAX)\n",
    "    cv2.normalize(img2,img2,0,255,norm_type=cv2.NORM_MINMAX)\n",
    "    a = np.array(img1 + noise1)\n",
    "    b = np.array(img2 + noise2)\n",
    "    cv2.normalize(a,a,0,255,norm_type=cv2.NORM_MINMAX)\n",
    "    cv2.normalize(b,b,0,255,norm_type=cv2.NORM_MINMAX)\n",
    "    a = a.astype(np.uint8)\n",
    "    b = b.astype(np.uint8)\n",
    "    noise_img_list_1.append(a)\n",
    "    noise_img_list_2.append(b)\n",
    "\n",
    "# show original and noise image \n",
    "fig = plt.figure(figsize=(10,10))\n",
    "for i in range(8):\n",
    "    fig.add_subplot(2, 4, i+1)\n",
    "    plt.axis(\"off\")\n",
    "    if i == 0 :\n",
    "        plt.imshow(img_list[0])\n",
    "        plt.title(\"Original Image\")\n",
    "    elif i == 4 :\n",
    "        plt.title(\"Original Image\")\n",
    "        plt.imshow(img_list[1])\n",
    "    elif i > 0 and i < 4 :\n",
    "        plt.imshow(noise_img_list_1[i-1])\n",
    "    elif i > 4 : \n",
    "        plt.imshow(noise_img_list_2[i-5])\n",
    "    \n",
    "    if i % 4 == 1:\n",
    "        plt.title(\"noise with σ = {}\".format(std_list[0]))\n",
    "    elif i % 4 == 2:\n",
    "        plt.title(\"noise with σ = {}\".format(std_list[1]))\n",
    "    elif i % 4 == 3:\n",
    "        plt.title(\"noise with σ = {}\".format(std_list[2]))\n",
    "\n",
    "plt.subplots_adjust(hspace=0, wspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement Original NLM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the original NLM algorithm with the same parameters as in [1].\n",
    "\n",
    "def gaussian_kernel(l, sig):\n",
    "    ax = np.arange(-l // 2 + 1., l // 2 + 1.)\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "    kernel = np.exp(-(xx**2 + yy**2) / (2. * sig**2))\n",
    "    final = kernel / kernel.sum()\n",
    "    return final\n",
    "\n",
    "def non_local_means_filter(noise_img):\n",
    "    outputs = np.zeros(noise_img.shape)\n",
    "    cv2.normalize(noise_img,noise_img,0,1,norm_type=cv2.NORM_MINMAX)\n",
    "    for t in (range(3)) :\n",
    "        image = noise_img[:,:,t]\n",
    "        [m, n] = image.shape\n",
    "        img = cv2.copyMakeBorder(image, 5, 5, 5, 5, cv2.BORDER_DEFAULT)\n",
    "        out = np.zeros((m, n), dtype='float')\n",
    "        kernel = gaussian_kernel(7, 1)\n",
    "        h = 21\n",
    "        h = h * h\n",
    "        for i in (range(6, m)):\n",
    "            for j in range(6,n):\n",
    "                w1 = img[i:i + 7, j:j + 7]\n",
    "                wmax = 0\n",
    "                avg = 0\n",
    "                sweight = 0\n",
    "                rmin = i - 2;rmax = i + 2;cmin = j - 2;cmax = j + 2\n",
    "                for r in range(rmin, rmax):\n",
    "                    for c in range(cmin, cmax):\n",
    "                        w2 = img[r - 3:r + 4, c - 3:c + 4]\n",
    "                        bl = w1 - w2\n",
    "                        temp = np.multiply(bl, bl)\n",
    "                        d = sum(sum(np.multiply(kernel, temp)))\n",
    "                        w = np.exp( -d / h)\n",
    "                        if w > wmax:\n",
    "                            wmax = w\n",
    "                        sweight = sweight + w\n",
    "                        avg = avg + w * img[r, c]\n",
    "\n",
    "                avg = avg + wmax * img[i, j]\n",
    "                sweight = sweight + wmax\n",
    "                if sweight > 0:\n",
    "                    out[i-5 , j-5 ] = avg / sweight\n",
    "                else:\n",
    "                    out[i-5 , j-5 ] = img[i, j]\n",
    "        outputs[:,:,t] = out\n",
    "    cv2.normalize(outputs,outputs,0,255,norm_type=cv2.NORM_MINMAX)\n",
    "    outputs = outputs.astype(np.uint8)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "nlmf_img = []\n",
    "for i in tqdm(range(8)):\n",
    "    fig.add_subplot(2, 4, i+1)\n",
    "    plt.axis(\"off\")\n",
    "    temp = np.zeros(img_list[0].shape)\n",
    "    if i == 0 :\n",
    "        temp = img_list[0]\n",
    "    elif i == 4 :\n",
    "        temp = img_list[1]\n",
    "    elif i > 0 and i < 4 :\n",
    "        temp = non_local_means_filter(noise_img_list_1[i-1])\n",
    "    elif i > 4 : \n",
    "        temp = non_local_means_filter(noise_img_list_2[i-5])\n",
    "    plt.imshow(temp)\n",
    "    nlmf_img.append(temp)\n",
    "    if i % 4 == 1:\n",
    "        plt.title(\"denoising with σ = {}\".format(std_list[0]))\n",
    "    elif i % 4 == 2:\n",
    "        plt.title(\"denoising with σ = {}\".format(std_list[1]))\n",
    "    elif i % 4 == 3:\n",
    "        plt.title(\"denoising with σ = {}\".format(std_list[2]))\n",
    "    elif i % 4 == 0 :\n",
    "        plt.title(\"Original Image\")\n",
    "end_time = time.time()\n",
    "print(\"Time : {} sec\".format(str(int(end_time-start_time))))\n",
    "plt.subplots_adjust(hspace=0, wspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Rotation and Mirror Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In NLM, finding many similar patches are crucial to the denoising quality. In the original\n",
    "# version [1], it only uses the candidate patches of the same orientation. However, if we consider\n",
    "# rotation and mirror symmetry of a patch, much more similar candidate patches can be obtained.\n",
    "# So, modify your algorithm so that you can utilize rotated and mirrored similar patches in the\n",
    "# search window.\n",
    "# For rotation-invariant patch matching, you may need to find the orientations of two patches and\n",
    "# normalize the orientations of them before matching. To determine the dominant orientation of a\n",
    "# patch, you can use the dominant gradient orientation as used in SIFT descriptor.\n",
    "\n",
    "def gaussian_kernel(l, sig):\n",
    "    ax = np.arange(-l // 2 + 1., l // 2 + 1.)\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "    kernel = np.exp(-(xx**2 + yy**2) / (2. * sig**2))\n",
    "    final = kernel / kernel.sum()\n",
    "    return final\n",
    "\n",
    "def dominant_gradient_orientation_nlm_filter(noise_img):\n",
    "    outputs = np.zeros(noise_img.shape)\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    cv2.normalize(noise_img,noise_img,0,1,norm_type=cv2.NORM_MINMAX)\n",
    "    for t in (range(3)) :\n",
    "        image = noise_img[:,:,t]\n",
    "        [m, n] = image.shape\n",
    "        img = cv2.copyMakeBorder(image, 7, 7, 7, 7, cv2.BORDER_DEFAULT)\n",
    "        out = np.zeros((m, n), dtype='float')\n",
    "        kernel = gaussian_kernel(7, 1)\n",
    "        h = 21\n",
    "        h = h * h\n",
    "        for i in (range(8, m)):\n",
    "            for j in range(8,n):\n",
    "                w1 = img[i:i + 7, j:j + 7]\n",
    "                # get dominant gradient orientation\n",
    "                gradient_w1_x = cv2.Sobel(w1,cv2.CV_64F,1,0,3)\n",
    "                gradient_w1_y = cv2.Sobel(w1,cv2.CV_64F,0,1,3)    \n",
    "                mag_w1 = np.sqrt(gradient_w1_x*gradient_w1_x+gradient_w1_y*gradient_w1_y)\n",
    "                angle_w1 = np.arctan2(gradient_w1_y,gradient_w1_x)\n",
    "                o_w1 = np.multiply(mag_w1,gaussian_kernel(7,1.5*3))\n",
    "                o_w1 -= np.max(angle_w1)\n",
    "                # \n",
    "                wmax = 0\n",
    "                avg = 0\n",
    "                sweight = 0\n",
    "                rmin = i - 2;rmax = i + 2;cmin = j - 2;cmax = j + 2\n",
    "                for r in range(rmin, rmax):\n",
    "                    for c in range(cmin, cmax):\n",
    "                        # get dominant gradient orientation\n",
    "                        w2 = img[r - 3:r + 4, c - 3:c + 4]\n",
    "                        gradient_w2_x = cv2.Sobel(w2,cv2.CV_64F,1,0,3)\n",
    "                        gradient_w2_y = cv2.Sobel(w2,cv2.CV_64F,0,1,3)\n",
    "                        mag_w2 = np.sqrt(gradient_w2_x*gradient_w2_x+gradient_w2_y*gradient_w2_y)\n",
    "                        angle_w2 = np.arctan2(gradient_w2_y,gradient_w2_x)\n",
    "                        o_w2 = np.multiply(mag_w2,gaussian_kernel(7,1.5*3))\n",
    "                        o_w2 -= np.max(angle_w2)\n",
    "                        #\n",
    "                        mm = np.subtract(o_w1,o_w2)\n",
    "                        bl = np.linalg.norm(mm)\n",
    "                        temp = np.multiply(bl, bl)\n",
    "                        d = sum(sum(np.multiply(kernel, temp)))\n",
    "                        w = np.exp(-d / h)\n",
    "                        if w > wmax:\n",
    "                            wmax = w\n",
    "                        sweight = sweight + w\n",
    "                        avg = avg + w * img[r, c]\n",
    "\n",
    "                avg = avg + wmax * img[i, j]\n",
    "                sweight = sweight + wmax\n",
    "                if sweight > 0:\n",
    "                    out[i-7 , j-7 ] = avg / sweight\n",
    "                else:\n",
    "                    out[i-7 , j-7 ] = img[i, j]\n",
    "        outputs[:,:,t] = out\n",
    "    w,h,_ = outputs.shape\n",
    "    cv2.normalize(outputs,outputs,0,255,norm_type=cv2.NORM_MINMAX)\n",
    "    outputs = outputs.astype(np.uint8)\n",
    "    return outputs\n",
    "\n",
    "start_time = time.time()\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "dgo_nlmf_img = []\n",
    "for i in tqdm(range(8)):\n",
    "    fig.add_subplot(2, 4, i+1)\n",
    "    plt.axis(\"off\")\n",
    "    temp = np.zeros(img_list[0].shape)\n",
    "    if i == 0 :\n",
    "        temp = img_list[0]\n",
    "    elif i == 4 :\n",
    "        temp = img_list[1]\n",
    "    elif i > 0 and i < 4 :\n",
    "        temp = dominant_gradient_orientation_nlm_filter(noise_img_list_1[i-1])\n",
    "    elif i > 4 : \n",
    "        temp = dominant_gradient_orientation_nlm_filter(noise_img_list_2[i-5])\n",
    "    plt.imshow(temp)\n",
    "    dgo_nlmf_img.append(temp)\n",
    "    if i % 4 == 1:\n",
    "        plt.title(\"denoising with σ = {}\".format(std_list[0]))\n",
    "    elif i % 4 == 2:\n",
    "        plt.title(\"denoising with σ = {}\".format(std_list[1]))\n",
    "    elif i % 4 == 3:\n",
    "        plt.title(\"denoising with σ = {}\".format(std_list[2]))\n",
    "    elif i % 4 == 0 :\n",
    "        plt.title(\"Original Image\")\n",
    "end_time = time.time()\n",
    "print(\"Time : {} sec\".format(str(int(end_time-start_time))))\n",
    "plt.subplots_adjust(hspace=0, wspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scale-space search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the Gaussian pyramid of the noisy image in three levels\n",
    "noise_img_list = [noise_img_list_1,noise_img_list_2]\n",
    "t = 1\n",
    "fig = plt.figure(figsize=(30,10))\n",
    "gaussian_pyramid_list = [] \n",
    "for noise_img in noise_img_list :\n",
    "    for idx in range(len(noise_img)) : \n",
    "        layer = noise_img[idx].copy()\n",
    "        gaussian_pyramid = [layer]\n",
    "        h,w,d = layer.shape\n",
    "        for i in range(2):\n",
    "            layer = cv2.pyrDown(layer)\n",
    "            gaussian_pyramid.append(layer)\n",
    "            w += layer.shape[1]\n",
    "        gaussian_pyramid_list.append(gaussian_pyramid)\n",
    "        pyr1 = np.ones((h,w,d))\n",
    "        w,w2,h,h2 = 0,0,0,0\n",
    "\n",
    "        for i in range(len(gaussian_pyramid)) :\n",
    "            layer = gaussian_pyramid[i]\n",
    "            w2 += layer.shape[1]\n",
    "            pyr1[h:,w:w2,:] = layer\n",
    "            h += layer.shape[0]//2\n",
    "            w += layer.shape[1]\n",
    "        fig.add_subplot(2, 3, t)\n",
    "        if t % 3 == 1 :\n",
    "            plt.title(\"Noise with with σ = 20\")\n",
    "        elif t % 3 == 2 :\n",
    "            plt.title(\"Noise with with σ = 30\")\n",
    "        elif t % 3 == 0 :\n",
    "            plt.title(\"Noise with with σ = 40\")\n",
    "        t+=1\n",
    "        cv2.normalize(pyr1,pyr1,0,255,norm_type=cv2.NORM_MINMAX)\n",
    "        pyr1 = pyr1.astype(np.uint8)\n",
    "        plt.imshow(pyr1)\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "plt.subplots_adjust(hspace=0.1, wspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to find the similar patches not only in the same scale but also in other scaled images. You\n",
    "# can keep the size of the search window the same in all scaled images.\n",
    "# Implement the original NLM algorithm with the same parameters as in [1].\n",
    "def gaussian_kernel(l, sig):\n",
    "    ax = np.arange(-l // 2 + 1., l // 2 + 1.)\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "    kernel = np.exp(-(xx**2 + yy**2) / (2. * sig**2))\n",
    "    final = kernel / kernel.sum()\n",
    "    return final\n",
    "\n",
    "def scale_local_means_filter(noise_img,gps):\n",
    "    outputs = np.zeros(noise_img.shape)\n",
    "    cv2.normalize(noise_img,noise_img,0,1,norm_type=cv2.NORM_MINMAX)\n",
    "    # padding\n",
    "    padding_gp = []\n",
    "    for gp in reversed(gps) :         \n",
    "        cv2.normalize(gp,gp,0,1,norm_type=cv2.NORM_MINMAX)\n",
    "        padding_gp.append(cv2.copyMakeBorder(gp, 5, 5, 5, 5, cv2.BORDER_DEFAULT))\n",
    "    for t in (range(3)) :\n",
    "        image = noise_img[:,:,t]\n",
    "        [m, n] = image.shape\n",
    "        img = cv2.copyMakeBorder(image, 5, 5, 5, 5, cv2.BORDER_DEFAULT)\n",
    "        out = np.zeros((m, n), dtype='float')\n",
    "        kernel = gaussian_kernel(7, 1)\n",
    "        h = 21\n",
    "        h = h * h\n",
    "        for i in (range(6, m)):\n",
    "            for j in range(6,n):\n",
    "                w1 = img[i:i + 7, j:j + 7]\n",
    "                wmax = 0\n",
    "                avg = 0\n",
    "                sweight = 0\n",
    "                rmin = i - 2;rmax = i + 2;cmin = j - 2;cmax = j + 2\n",
    "                for gp in padding_gp :\n",
    "                    if rmax + 4 > gp.shape[0] or cmax + 4 > gp.shape[1] :\n",
    "                        continue\n",
    "                    for r in range(rmin, rmax):\n",
    "                            for c in range(cmin, cmax):\n",
    "                                w2 = gp[r - 3:r + 4, c - 3:c + 4,t]\n",
    "                                bl = w1 - w2\n",
    "                                d = np.multiply(bl, bl)\n",
    "                                d = np.multiply(kernel,d)\n",
    "                                d = np.linalg.norm(d)\n",
    "                                w = np.exp(d / h)\n",
    "                                if w > wmax:\n",
    "                                    wmax = w\n",
    "                                sweight = sweight + w\n",
    "                                avg = avg + w * img[r, c]\n",
    "\n",
    "                avg = avg + wmax * img[i, j]\n",
    "                sweight = sweight + wmax\n",
    "                if sweight > 0:\n",
    "                    out[i-5 , j-5 ] = avg / sweight\n",
    "                else:\n",
    "                    out[i-5 , j-5 ] = img[i, j]\n",
    "        outputs[:,:,t] = out\n",
    "    cv2.normalize(outputs,outputs,0,255,norm_type=cv2.NORM_MINMAX)\n",
    "    outputs = outputs.astype(np.uint8)\n",
    "    return outputs\n",
    "\n",
    "start_time = time.time()\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "scale_nlmf_img = []\n",
    "for i in tqdm(range(8)):\n",
    "    fig.add_subplot(2, 4, i+1)\n",
    "    plt.axis(\"off\")\n",
    "    temp = np.zeros(img_list[0].shape)\n",
    "    if i == 0 :\n",
    "        temp = img_list[0]\n",
    "    elif i == 4 :\n",
    "        temp = img_list[1]\n",
    "    elif i > 0 and i < 4 :\n",
    "        temp = scale_local_means_filter(noise_img_list_1[i-1],gaussian_pyramid_list[i-1])\n",
    "    elif i > 4 : \n",
    "        temp = scale_local_means_filter(noise_img_list_2[i-5],gaussian_pyramid_list[i-2])\n",
    "    plt.imshow(temp)\n",
    "    scale_nlmf_img.append(temp)\n",
    "    if i % 4 == 1:\n",
    "        plt.title(\"denoising with σ = {}\".format(std_list[0]))\n",
    "    elif i % 4 == 2:\n",
    "        plt.title(\"denoising with σ = {}\".format(std_list[1]))\n",
    "    elif i % 4 == 3:\n",
    "        plt.title(\"denoising with σ = {}\".format(std_list[2]))\n",
    "    elif i % 4 == 0 :\n",
    "        plt.title(\"Original Image\")\n",
    "end_time = time.time()\n",
    "print(\"Time : {} sec\".format(str(int(end_time-start_time))))\n",
    "plt.subplots_adjust(hspace=0, wspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSNR\n",
    "#### Report the quality of the filtered images using PSNR and the running time for each algorithm you have implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PSNR(original, noise_img, maxi=255):\n",
    "    mse = np.mean((original-noise_img)**2)\n",
    "    if mse == 0 :\n",
    "        return 100\n",
    "    PSNR = 20*math.log10(maxi/math.sqrt(mse))\n",
    "    \n",
    "    return PSNR\n",
    "#\n",
    "img1 = np.array(img_list[0], copy=True) \n",
    "img2 = np.array(img_list[1], copy=True)\n",
    "cv2.normalize(img1,img1,0,255,norm_type=cv2.NORM_MINMAX)\n",
    "cv2.normalize(img2,img2,0,255,norm_type=cv2.NORM_MINMAX)\n",
    "\n",
    "print(\"--------------------------------------------------------------PSNR SCORE--------------------------------------------------------------\")\n",
    "for i in range(1,len(nlmf_img)) :\n",
    "    psnr4=\n",
    "    if i < 4 : \n",
    "        psnr1 = get_PSNR(img1,noise_img_list_1[i-1])\n",
    "        psnr2 = get_PSNR(img1,nlmf_img[i])\n",
    "        psnr3 = get_PSNR(img1,dgo_nlmf_img[i])\n",
    "        psnr4 = get_PSNR(img1,scale_nlmf_img[i])\n",
    "        print(\"Noise image1 with σ = {} : {:6.5} | NLM filter : {:6.5} | Dominant Orientation gradient NLM filter : {:.5} | Scale Space Search : {:.5}\".format(std_list[i-1],psnr1,psnr2,psnr3,psnr4))\n",
    "    elif i == 4:\n",
    "        continue\n",
    "    else :\n",
    "        psnr1 = get_PSNR(img2,noise_img_list_2[i-5])\n",
    "        psnr2 = get_PSNR(img2,nlmf_img[i])\n",
    "        psnr3 = get_PSNR(img2,dgo_nlmf_img[i])\n",
    "        psnr4 = get_PSNR(img2,scale_nlmf_img[i])\n",
    "        print(\"Noise image2 with σ = {} : {:6.5} | NLM filter : {:6.5} | Dominant Orientation gradient NLM filter : {:.5} | Scale Space Search : {:.5}\".format(std_list[i-5],psnr1,psnr2,psnr3,psnr4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
